%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Some auxiliary results on convex functions}
\label{Sec:AuxiliaryResults}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

In this appendix we present some auxiliary results concerning convex functions. Recall that for measurable functions $f:\R\to \R$, convexity in an open interval $I$ is equivalent to midpoint convexity, i.e.,
$$
\dfrac{f(x) + f(y)}{2} \geq f \left( \dfrac{x+y}{2}\right) \quad \textrm{ for every } x,\, y \in I\,,
$$
and the same is true for strict convexity with an strict inequality
(see Chapter~1 of \cite{Niculescu} and the references therein).


The main result, used in the characterization of $\lcal_\star$ in Theorem~\ref{Th:CharacterizationLstar}, is the following.

\begin{proposition}
	\label{Prop:EquivalenceK(sqrt)Convex<->Inequality}
	Let $K:(0, +\infty) \to (0,+\infty)$ be a continuous and nonincreasing function such that
	$$
	\lim_{z\to +\infty} K(z) = 0\,.
	$$
	Then, the following statements are equivalent:
	\begin{enumerate}
		\item[i)] $K(\sqrt{z})$ is strictly convex in $(0, +\infty)$.
		\item[ii)] For every $c_1$, $c_2$, $A$, $B$, $C$ and $D$ satisfying
		\begin{enumerate}
			\item $c_1 > 0$, $c_2>0$.
			\item $A$, $B$, $C$, $D \in (0, 1/c_2)$.
			\item $A = \max\{A,\, B,\, C,\, D\}$.
			\item $A + D \geq B + C$.
		\end{enumerate}
		it holds
		$$
		g(A) + g(D) \geq g(B) + g(C)\,,
		$$
		where
		$$
		g(z) := K(c_1 \sqrt{1 + c_2z}) + K(c_1 \sqrt{1 - c_2z})\,.
		$$
		Moreover, equality holds if and only if
		$$ A = B \ \ \ \ \textrm{ and} \ \ \ \ C=D, $$
		or
		$$ A = C \ \ \ \ \textrm{ and} \ \ \ \ B=D. $$
	\end{enumerate}
\end{proposition}



To prove this proposition, we need some lemmas on convex functions. The first one is the following.

\begin{lemma}
\label{Lemma:Convex<->AllReflectionsConvex} Let $h: I \subset \R \to \R$ be a function defined in
an open interval $I$ such that it is measurable. Then, $h(z)$ is convex in $I$ if and only if
$\widetilde{h}_c(z) := h(c+z) + h(c-z)$ is convex in $I_c := (-\dist\{c, \partial I\}, \dist\{c,
\partial I\})$ for every $c\in I$. The statement remains true if we replace convexity by strict
convexity, concavity or strict concavity.
\end{lemma}

\begin{proof}
First, let us assume that $h$ is convex in $I$. We call
$$
x_+ = c + x\,, \quad x_- = c - x\,, \quad y_+ = c + y\,, \quad \textrm{ and } \quad y_- = c - y\,.
$$
Then, if $x$, $y\in I_c$, we have that $x_+$, $x_-$, $y_+$, $y_- \in I$. Hence, for all $t\in(0,1)$,
\begin{align*}
t\widetilde{h}_c(x) + (1-t)\widetilde{h}_c(y)
&=  th(x_+) + (1-t)h(y_+) + t h(x_-) + (1-t)h(y_-) \\
&\geq h(tx_+ + (1-t)y_+) + h(tx_- + (1-t)y_-) \\
&= h(c + tx + (1-t)y) + h(c-tx + (1-t)y) \\
& = \widetilde{h}_c(tx + (1-t)y)\,.
\end{align*}
Therefore, $\widetilde{h}_c(z)$ is convex in $I_c$ for every $c\in I$.

Assume now that $\widetilde{h}_c(z)$ is convex in $I_c$ for every $c\in I$. By contradiction,
suppose that $h$ is not convex in $I$. Then, there exist some $x$, $y\in I$ such that
\begin{equation}
\label{Eq:ContradictionConvexity}
\dfrac{h(x) + h(y)}{2} < h \left (\dfrac{x+y}{2}\right )\,.
\end{equation}

Let $c = (x+y)/2$ and thus
$$
\widetilde{h}_c(z) = h\left( \dfrac{x+y}{2} + z\right) +  h\left( \dfrac{x+y}{2} - z\right)\,.
$$
Define $ x_0 := (x-y)/2$ and $y_0:= (y-x)/2$. It is clear that $x_0$, $y_0\in I_c$. Therefore,
$$
h(x) + h(y) = \dfrac{1}{2} \left( \widetilde{h}_c(x_0) + \widetilde{h}_c(y_0)\right )
\geq \widetilde{h}_c \left( \dfrac{x_0 + y_0}{2}\right )
= 2 h \left (\dfrac{x+y}{2}\right )\,,
$$
and this contradicts \eqref{Eq:ContradictionConvexity}. Hence, $h$ is convex in $I$.
\end{proof}

From this result we deduce an immediate corollary.

\begin{corollary}
\label{Cor:gConvex<->K(sqrt)convex} Let $K:(0,+\infty) \to (0,+\infty)$ be a measurable function.
Then, given any $c_1,c_2>0$, the function
$$
g(z) := K \left (c_1 \sqrt{1 + c_2 z}\right) +  K \left (c_1 \sqrt{1 - c_2 z}\right)
$$
is  (strictly) convex in $(-1/c_2, 1/c_2)$ for every $c_1>0$ if and only if $K(\sqrt{z})$ is
(strictly) convex in $(0, +\infty)$.
\end{corollary}
\begin{proof}
Since we can rewrite $g$ as
$$
g(z) = K \left (\sqrt{c_1^2 + c_1^2c_2 z}\right) +  K \left (\sqrt{c_1^2 - c_1^2c_2 z}\right),
$$
it is clear that $g$ is  (strictly) convex in $(-1/c_2, 1/c_2)$ for every $c_1>0$ if and only if
$$
K \left(\sqrt{c_1^2 + z}\right) +  K \left(\sqrt{c_1^2 - z}\right)
$$
is (strictly) convex in $(-c_1^2, c_1^2)$ for every $c_1>0$. Then, by applying
Lemma~\ref{Lemma:Convex<->AllReflectionsConvex} with $I = (0,+\infty)$, this is equivalent to the
convexity of $K(\sqrt{z})$ in $(0, +\infty)$.
\end{proof}

The following is a characterization of the nondecreasing convex functions.

\begin{lemma}
\label{Lemma:InequalitConvexFunctions} Let $g \colon I\subset \R \to \R$ be a function defined in
an open interval $I$ such that $g$ is measurable and nondecrasing in $I$. Then, we have the
following equivalences:
\begin{enumerate}
\item[i)] $g$ is strictly convex in $I$.
\item[ii)] For any given real numbers $A$, $B$, $C$, $D$ $\in I$ such that
\begin{equation}
\label{Eq:AssumptionsInequalitiesABCD}
\begin{cases}
A = \max\{A,B,C,D\}\,, \\
A + D \geq B + C\,,
\end{cases}
\end{equation}
it is satisfied that
$$
g(A) + g(D) \geq g(B) + g(C),
$$
and equality holds if and only if
$$ A = B \ \ \ \ \textrm{ and} \ \ \ \ C=D, $$
or
$$ A = C \ \ \ \ \textrm{ and} \ \ \ \ B=D. $$
\end{enumerate}

\end{lemma}
\begin{proof}
$i)\, \Rightarrow \,ii)$ First note that if $g$ is strictly convex, then $g$ is continuous in $I$ and differentiable except for, at most, a countable set of points. Moreover, $g'$ is increasing in the regular points. In addition, since $g$ is strictly convex and nondecreasing, it is in fact increasing.

Without loss of generality, we can assume that $B \geq C$. Now, we distinguish two cases:


$\bullet$ $D \geq C$

The inequality $g(A) + g(D) \geq g(B) + g(C)$ is trivial by the monotonicity of $g$. Moreover, if $A>B$ or $D>C$ we obtain the strict inequality since $g$ is increasing.

$\bullet$ $D < C$

If $A = B$ we arrive at a contradiction from \eqref{Eq:AssumptionsInequalitiesABCD}. Then, we have
$A > B \geq C > D$.

Since $g$ is piecewise $C^1$, let $\{z_i\}_{i=1}^{n}$ be the points in the interval $(B,A)$ where
the function is not differentiable, with $z_0 = B$ and $z_{n+1}=A$, and let
$\{\bar{z}_i\}_{i=1}^{m}$ be the same for the interval $(D,C)$ with $\bar{z}_0 = D$ and
$\bar{z}_{m+1}=C$.

By applying Taylor's theorem in each interval of differentiability and adding the expressions we
obtain
$$
g(A) = g(B) + \sum_{i=0}^{n}(z_{i+1}-z_i) g'(\xi_i) \quad \textrm{ with } \xi_i \in (z_i,z_{i+1})\,,
$$
and
$$
g(C) = g(D) + \sum_{i=0}^{m}(\bar{z}_{i+1}-\bar{z}_i) g'(\bar{\xi}_i) \quad \textrm{ with } \bar{\xi}_i \in (\bar{z}_i,\bar{z}_{i+1})\,,
$$
If we define $\xi = \xi_0 $ and $\bar{\xi} = \bar{\xi}_m$, since $g'$ is nondecreasing at the regular points we get
$$
g(A) \geq g(B) + \sum_{i=0}^{n}(z_{i+1}-z_i) g'(\xi) = g(B) + (A-B)g'(\xi),
$$
and
$$
g(C) \leq g(D) + \sum_{i=0}^{m}(\bar{z}_{i+1}-\bar{z}_i) g'(\bar{\xi}) = g(D)+(C-D)g'(\bar{\xi}) .
$$
It is clear that $\xi > \overline{\xi}$ and thus $g'(\xi) > g'(\overline{\xi})$. Therefore,
\begin{align*}
g(A) + g(D) - g(B) - g(C) &= (g(A) - g(B)) - (g(C) - g(D)) \\
&\geq (A - B)g'(\xi)  - (C - D)g'(\overline{\xi}) \\
&= (A - B - C + D)g'(\xi) + (C - D) (g'(\xi) - g'(\overline{\xi}))\\
& > 0\,,
\end{align*}
where we have used that $A - B - C + D \geq 0$, $C - D > 0$, $g'\geq 0$ in the regular points and
$g'(\xi) > g'(\overline{\xi})$.

$ii)\, \Rightarrow \,i)$ Given $x\neq y$ in $I$, that we can suppose $x>y$ without loss of generality, we take $A=x$, $B=C=(x+y)/2$ and $D=y$. Then we get $ g(x)+g(y) > 2g\left( (x+y)/2 \right)$.
\end{proof}

\begin{remark}
\label{Remark:InequalitConvexFunctions} Note that the condition of strict convexity is only needed
in order to characterize when the equality is satisfied. That is, with only a convexity condition
we also obtain the inequality of statement $ii)$, although we are not able to determine when equality is satisfied.
\end{remark}
\begin{remark}
\label{Remark:LeftImplicationDoNotRequireNondecreasing}
The deduction of $i)$ from $ii)$ does not require $g$ to be nondecreasing.
\end{remark}

An equivalent version of the previous result but for nonincreasing functions is the following.

\begin{corollary}
\label{Cor:hDecreasingConvex} Let $h \colon I\subset \R \to \R$ be a measurable and nonincreasing function defined in an open
interval $I$. Then, we have the following
equivalences:
\begin{enumerate}
\item[i)] $h$ is convex in $I$.
\item[ii)] For any given real numbers $a$, $b$, $c$, $d$ $\in I$ such that
\begin{equation*}
%\label{Eq:AssumptionsInequalitiesabcd}
\begin{cases}
a \geq b \geq c \geq d \,, \\
a + d \leq b + c\,,
\end{cases}
\end{equation*}
it is satisfied that
$$ h(a) + h(d) \geq h(b) + h(c)\,.$$
\end{enumerate}
\end{corollary}

\begin{proof}
Let us define $g(z) = h(a-z)$. It is clear that since $h$ is measurable and nonincreasing, then $g$
is measurable and nondecreasing. On the other hand, let $A=a-d$, $B=a-c$, $C=a-b$ and $D=0$. Then,
we have that condition $a \geq b \geq c \geq d$ is equivalent to $A\geq B \geq C \geq D$ and
condition $a+d\leq b+c$ is equivalent to $A+D\geq B+C$. Therefore, we can apply Lemma
\ref{Lemma:InequalitConvexFunctions}, taking into account Remark
\ref{Remark:InequalitConvexFunctions}, and the desired equivalence is obtained.
\end{proof}

The last result we need to establish Proposition~\ref{Prop:EquivalenceK(sqrt)Convex<->Inequality} is the following.

\begin{lemma}
\label{Lemma:gNondecreasing}
Let $K:(0,+\infty) \to (0,+\infty)$ be a measurable function such that
$$ \lim_{z\to+\infty} K(z) = 0 $$
and $ K(\sqrt{z}) $ is convex/strictly convex in $(0,+\infty)$. Then, given any $c_1,c_2>0$ the
function
$$
g(z) := K(c_1 \sqrt{1 + c_2 z}) +  K(c_1 \sqrt{1 - c_2 z})
$$
is nondecreasing/increasing in $(0, 1/c_2)$.
\end{lemma}

\begin{proof}
First, note that from the hypothesis of $K$ we can deduce that $K(\sqrt{z})$, and also
$K(c_1\sqrt{z})$, is convex and nonincreasing.

Now, given $x\geq y$, we have
\begin{align*}
g(x)-g(y) &= K(c_1\sqrt{1+c_2 x}) + K(c_1\sqrt{1-c_2 x}) \\
&\ \ \ \ - K(c_1\sqrt{1+c_2 y}) -K(c_1\sqrt{1-c_2 y}) \geq 0,
\end{align*}
where we have applied Corollary~\ref{Cor:hDecreasingConvex} with $h(z) = K(c_1\sqrt{z})$,
$a=1+c_2x$, $b=1+c_2y$, $c=1-c_2y$ and $d=1-c_2x$.
\end{proof}

\begin{remark}
	\label{Remark:Concavity}
If we assume that $K$ is nonincreasing and concave, then we can prove in a similar way that $g$ is
nondecreasing.
\end{remark}

With all these results at hand we can now prove Proposition~\ref{Prop:EquivalenceK(sqrt)Convex<->Inequality}.

\begin{proof}[Proof of Proposition~\ref{Prop:EquivalenceK(sqrt)Convex<->Inequality}]
$i)\, \Rightarrow \,ii)$ By Lemma~\ref{Lemma:gNondecreasing} and
Corollary~\ref{Cor:gConvex<->K(sqrt)convex}, $g$ is strictly convex in
$(-1/c_2,1/c_2)$ and nondecreasing in $(0,1/c_2)$ for all $c_2>0$. Therefore, point $ii)$ follows from
Lemma~\ref{Lemma:InequalitConvexFunctions}.

$ii)\, \Rightarrow \,i)$ By Lemma~\ref{Lemma:InequalitConvexFunctions} and in view of
Remark~\ref{Remark:LeftImplicationDoNotRequireNondecreasing}, $g$ is strictly convex in
$(-1/c_2,1/c_2)$ for all $c_2>0$. Hence, using Corollary~\ref{Cor:gConvex<->K(sqrt)convex} we deduce
that $K(\sqrt{z})$ is strictly convex in $(0, +\infty)$.
\end{proof}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{An auxiliary computation}
\label{Sec:AuxiliaryResults2}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

In this appendix we present an auxiliary computation that is needed in Section~\ref{Sec:OperatorOddF} in order to characterize the operators that belong to $\lcal_\star$.

\begin{lemma}
\label{Lemma:ComputationABCD} Let $\alpha$, $\beta$ be two real numbers satisfying $\alpha \geq
|\beta|$. Let $x=(x',x'')$, $y=(y',y'')\in \ocal \subset \R^{2m}$. Define
$$
\begin{array}{cc}
	A = |x'||y'|  \alpha + |x''||y''|\beta \,, \ \ \ \ \ &
	B = |x'||y''| \alpha + |x''||y'| \beta \,, \\
	C = |x''||y'| \alpha + |x'||y''| \beta \,, \ \ \ \ \ &
	D = |x''||y''|\alpha + |x'||y'|  \beta \,.
\end{array}
$$
Then,
\begin{enumerate}
\item It holds
$$
\begin{cases}
|A| \geq |B|,\ |A| \geq|C|, \ |A| \geq|D|\,, \\
|A| + |D| \geq |B| + |C|\,.
\end{cases}
$$
\item If either
$$ |A| = |B| \ \ \ \ \textrm{ and} \ \ \ \ |C| = |D|, $$
or
$$ |A| = |C| \ \ \ \ \textrm{ and} \ \ \ \ |B| = |D|, $$
then necessarily $\alpha = \beta = 0$.
\end{enumerate}

\end{lemma}
\begin{proof} The proof is elementary but requires to check some cases. In all of them we will use the following inequalities. Since $\alpha \geq |\beta |$,
$$
\alpha\geq 0 \quad \textrm{ and } \quad  -\alpha \leq \beta \leq \alpha\,.
$$
Moreover, since $x,y\in\ocal$, it holds
$$
|x'|>|x''| \quad \textrm{ and } \quad |y'|>|y''|\,.
$$


We start establishing the first statement. We show that $A\geq 0$ and that
$$
A \geq |B|, \ A \geq |C| ,\ A \geq |D|\,.
$$


- $A \geq 0$:
$$
 A =  |x'||y'|  \alpha + |x''||y''|\beta \geq (|x'||y'|  - |x''||y''|)\alpha \geq 0\,.
$$

- $A \geq |B|$:
$$
A\pm B = (|x'|\alpha-|x''|\beta)(|y'|\pm |y''|) \geq 0\,.
$$

- $A \geq |C|$:
$$
A\pm C = (|y'|\alpha-|y''|\beta)(|x'|\pm |x''|)  \geq 0\,.
$$

- $A \geq |D|$:
$$
A\pm D = (|x'||y'| \pm |x''||y''|)(\alpha \pm \beta) \geq 0\,.
$$


It remains to show
$$
A + |D| \geq |B| + |C|\,.
$$
The proof of this fact is just a computation considering all the eight possible configurations of
the signs of $B$, $C$ and $D$. Since the roles of $B$ and $C$ are completely interchangeable, we
may assume that $B \geq C$ and we only need to check six cases. To do it, note first that
\begin{equation}
\label{Eq:LemmaABCDProof1}
A + D - B - C = (|x'|-|x''|)(|y'|-|y''|)(\alpha + \beta) \geq 0 \,,
\end{equation}
\begin{equation}
\label{Eq:LemmaABCDProof2}
A - D - B + C = (|x'|+|x''|)(|y'|-|y''|)(\alpha - \beta) \geq 0 \,,
\end{equation}
and
\begin{equation}
\label{Eq:LemmaABCDProof3}
A + D + B + C = (|x'|+|x''|)(|y'|+|y''|)(\alpha + \beta) \geq 0 \,,
\end{equation}
With these three relations at hand we check the six cases.

- If $B \geq 0$, $C \geq 0$ and $D \geq 0$, then by \eqref{Eq:LemmaABCDProof1} we have
$$
A + |D| - |B| - |C| = A + D - B - C \geq 0\,.
$$

- If $B \geq 0$, $C \geq 0$ and $D \leq 0$, we use the sign of $D$ and \eqref{Eq:LemmaABCDProof1} to
see that
$$
A + |D| - |B| - |C| = A - D - B - C =  (A + D - B - C) + (-2D) \geq 0\,.
$$

- If $B \geq 0$, $C \leq 0$ and $D \geq 0$, we use the sign of $D$ and \eqref{Eq:LemmaABCDProof2} to
see that
$$
A + |D| - |B| - |C| = A + D - B + C =  (A - D - B + C) + 2D \geq 0\,.
$$

- If $B \geq 0$, $C \leq 0$ and $D \leq 0$, then by \eqref{Eq:LemmaABCDProof2} we have
$$
A + |D| - |B| - |C| = A - D - B + C \geq 0\,.
$$

- If $B \leq 0$, $C \leq 0$ and $D \geq 0$, then by \eqref{Eq:LemmaABCDProof3} we have
$$
A + |D| - |B| - |C| = A + D + B + C \geq 0\,.
$$

- If $B \leq 0$, $C \leq 0$ and $D \leq 0$, we use the sign of $D$ and \eqref{Eq:LemmaABCDProof3} to see that
$$
A + |D| - |B| - |C| = A - D + B + C =  (A + D + B + C) + (-2D) \geq 0\,.
$$

This concludes the proof of the first statement.

We prove now the second point of the lemma. Since the roles of $B$ and $C$ are completely
interchangeable, we only need to show the result in the case $|A| = |B|$ and $|C| = |D|$.

Recall that $A \geq 0$. Hence, since $A = |B|$ and $|C| = |D|$, a simple computation shows that
$$
\alpha = \sign (B) \dfrac{|x''|}{|x'|}\beta \quad \textrm{ and } \quad
\beta = \sign (C) \sign(D) \dfrac{|x''|}{|x'|} \alpha \,.
$$
Hence, combining both equalities we obtain
$$
\alpha = \sign (B) \sign (C) \sign(D) \dfrac{|x''|^2}{|x'|^2} \alpha.
$$
Finally, if we assume $\alpha \neq 0$, then necessarily $\sign (B) \sign (C) \sign(D)=1$ and $|x'|
= |x''|$, but this is a contradiction with $x\in \ocal$. Therefore, $\alpha = 0$ and thus $\beta =
0$.
\end{proof}








%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{The integro-differential operator $L_K$ in the $(s,t)$ variables}
\label{Sec:stcomputations}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

The goal of this appendix is to take advantage of the doubly radial symmetry of the functions we
are dealing with to write equation \eqref{Eq:NonlocalAllenCahn} in $(s,t)$ variables, passing from
an equation in $\R^{2m}$ to an equation in $(0,+\infty)\times (0,+\infty)\subset \R^2$.

\begin{lemma}
\label{Lemma:OperatorInSTVariables} Let $m \geq 1$, $\s\in(0,1)$ and let $w\in
C_{\loc}^\alpha(\R^{2m})$ with $\alpha > 2\s$ be a doubly radial function, i.e., depending only on
the variables $s$ and $t$. Let $L_K$ be a rotational invariant operator ($K(y) = K(|y|)$) of the form
\eqref{Eq:DefOfLu}. Then, if we define $\tilde{w}:(0,+\infty)\times (0,+\infty) \to \R$ as
$\tilde{w}(s,t) = w(s,0,...,0,t,0,...,0)$, it satisfies
$$ L_Kw(x) = \tilde{L}_K \tilde{w} (|x'|,|x''|), $$
with
%Then, for any $x = (s x_s, t x_t)$ with $x_s$, $x_t$ $\in \Sph^{m-1}$ ($x_s$, $x_t = \pm 1$ in the
%case $m=1$), $Lu(x)$ can be written in the following way:\todo{Is singular in $s=0$ or $t=0$??}
\begin{equation*}
\label{Eq:OperatorInSTVariables}
\widetilde{L}_K \tilde{w} (s,t) := \int_0^{+\infty}  \int_0^{+\infty} \sigma^{m-1} \tau^{m-1} \big(u(s,t) - u(\sigma, \tau)\big) J(s,t,\sigma, \tau)  \d \sigma\d \tau\,,
\end{equation*}
where:
\begin{enumerate}
	\item If $m= 1$,
	\begin{equation}
		\label{Eq:KernelInSTVariablesR2}
	J(s,t,\sigma, \tau) := \sum_{i=0}^1  \sum_{j =0}^1  K\Big(\sqrt{s^2 + t^2 + \sigma^2 + \tau^2 -2 s \sigma (-1)^i -2 t \tau (-1)^j}\Big)\,.
	\end{equation}
	
	\item If $m\geq 2$,
	\begin{align}
	J(s,t,\sigma, \tau) &:= c_m ^2  \int_{-1}^1  \int_{-1}^1  (1-\theta^2)^{\frac{m-2}{2}} (1-\overline{\theta}^2)^{\frac{m-2}{2}} \nonumber\\
	& \quad \quad \quad \quad \quad
	K\Big(\sqrt{s^2 + t^2 + \sigma^2 + \tau^2 -2 s \sigma \theta -2 t \tau \overline{\theta}}\Big) \d \theta \d \overline{\theta}\,, \label{Eq:KernelSTVariables2}
	\end{align}
	with
	$$
	c_m = \dfrac{2 \pi^{\frac{m-1}{2}}}{\Gamma (\frac{m-1}{2})}.
	$$
\end{enumerate}
%To compute it one should split three cases:
%$
%c_m = \begin{cases}  \dfrac{1}{\pi^2} & m= 2 \,,\\
%1 &  m= 3\,,\\
%\ds 4\pi^2 \prod_{k=1}^{m-3} \bpar{\int_0^\pi \sin^k \theta \d \theta }^2 & m \geq 4\,.
%\end{cases}
%$}
\end{lemma}


\begin{proof}
%We start with the case $m=1$. In this case, we will use explicitly that since $u$ is a function of
%$s$ and $t$, then $u$ is even with respect to the coordinate axis. Using this symmetry and the
%change $y = -\tilde{y}$, we have
%$$
%Lu(x) = \int_{\{y_2 > - y_1\}} \big( u(x) - u(y)\big) \{K(|x - y|) + K(|x + y|)\} \d y\,.
%$$
%If we call
%$$
%I(\Omega, x) := \int_{\Omega} \big( u(x) - u(y)\big) \{K(|x - y|) + K(|x + y|)\} \d y\,,
%$$
%then
%$$
%Lu(x) = I(\{y_2 > |y_1|\},x) + I(\{y_1 > |y_2|\},x)\,.
%$$
%We will check that $I(\{y_2 > |y_1|\},x)$ can be written in the form
%\eqref{Eq:OperatorInSTVariables} (integrated in the set $\tau > \sigma$). The computations for
%$I(\{y_1 > |y_2|\},x)$ are completely analogous.
%
%First, note that the set $\{y_2 > |y_1|\}$ can be written as
%$$
%\{y_2 > y_1 > 0\} \cup \phi(\{y_2 > y_1 > 0\}) \cup \{y_2 > 0, y_1 =0\}
%$$
%where $\phi$ is the reflection with respect to the $y_2$-axis. Therefore,
%\begin{align*}
%I(\{y_2 > |y_1|\}, x) & = \int_{\{y_2 > y_1 > 0\}} \big( u(x) - u(y)\big) \{K(|x - y|) + K(|x + y|)\} \d y  \\
%& \quad \quad + \int_{\phi(\{y_2 > y_1 > 0\})} \big( u(x) - u(y)\big) \{K(|x - y|) + K(|x + y|)\} \d y\,.
%\end{align*}
%By performing the change $\phi = \phi^{-1}$ in the second integral and using the symmetry of $u$,
%we end up with
%\begin{align*}
%I(\{y_2 > |y_1|\}, x) &=
%\int_{\{y_2 > y_1 > 0\}} \big( u(x) - u(y)\big) \cdot\\
%& \quad \quad \left \{K(|x - y|) + K(|x + y|) + K(|x - \phi_1(y)|) + K(|x + \phi_1(y)|) \right \} \d y\,.
%\end{align*}
%Then, if in the previous expression we write
%$$
%x = (s \sign(x_1), t \sign(x_2)) \quad \textrm{ and } \quad = (\sigma \sign(y_1), \tau \sign(y_2))\,,
%$$
%we find that
%$$
%I(\{y_2 > |y_1|\}, x) =
%\int_0^{\infty} \! \! \d \sigma \int_\sigma^{\infty} \! \! \d \tau \ \   \big( u(s,t) - u(\sigma, \tau)\big) J(s,t,\sigma, \tau)\,,
%$$
%with $J$ as in \eqref{Eq:KernelInSTVariablesR2}. Indeed, in $\{y_2 > y_1 > 0\}$ we have that
%$y=(\sigma, \tau)$, and it is not difficult to check that the expression
%$$
%K(|x - y|) + K(|x + y|) + K(|x - \phi_1(y)|) + K(|x + \phi_1(y)|)
%$$
%does not depend on $\sign(x_1)$ nor $\sign(x_1)$, so we can assume that $x=(s,t)$ and then
%\begin{align*}
%K(|x - y|) + K(|x + y|) + K(|x - \phi_1(y)|) + K(|x + \phi_1(y)|) = \\
%K\Big(\sqrt{s^2 + t^2 + \sigma^2 + \tau^2 + 2 s \sigma + 2 t \tau }\Big) +  K\Big(\sqrt{s^2 + t^2 + \sigma^2 + \tau^2 + 2 s \sigma  -2 t \tau }\Big) \\
%\quad + K\Big(\sqrt{s^2 + t^2 + \sigma^2 + \tau^2 -2 s \sigma + 2 t \tau }\Big) + K\Big(\sqrt{s^2 + t^2 + \sigma^2 + \tau^2 -2 s \sigma  -2 t \tau }\Big)\,.
%\end{align*}
%
%In a completely analogous way, we find that
%$$
%I(\{y_1 > |y_2|\},x) = \int_0^{\infty} \! \! \d \sigma \int_0^\sigma \! \! \d \tau \ \   \big( u(s,t) - u(\sigma, \tau)\big) J(s,t,\sigma, \tau)\,,
%$$
%and hence
%$$
%Lu(x) = \int_0^{\infty} \! \! \d \sigma \int_0^\infty \! \! \d \tau \ \   \big( u(s,t) - u(\sigma, \tau)\big) J(s,t,\sigma, \tau) =: \widetilde{L}u(s,t)\,.
%$$
%This concludes the proof when $m=1$.
%	
%We deal now with the case $m=2$.
Let $x = (s x_s, t x_t)$ with $x_s$, $x_t$ $\in \Sph^{m-1}$ and $y = (\sigma y_\sigma, \tau
y_\tau)$ with $y_\sigma$, $y_\tau$ $\in \Sph^{m-1}$. Then, decomposing $\R^{2m} = \R^m \times \R^m$
and using polar coordinates in each $\R^m$ we obtain
\begin{align*}
L_Ku(x) &= \int_{\R^{2m}} \big( u(x) - u(y)\big) K( |x-y|) \d y &\\
&= \int_0^{+\infty}  \int_0^{+\infty} \sigma^{m-1} \tau^{m-1} \big(u(s,t) - u(\sigma, \tau)\big)  \\
&\quad \quad \quad \quad  \bpar{\int_{\Sph^{m-1}}  \int_{\Sph^{m-1}} K \Big( \sqrt{|sx_s - \sigma y_\sigma|^2 + |t x_t - \tau y_\tau|^2 } \Big) \d y_\sigma \d y_\tau } \d \sigma \d \tau
\end{align*}
Now, we define the kernel
\begin{equation}
\label{Eq:KernelSTVariablesProof1}
J(x_s, x_t, s,t,\sigma, \tau) := \int_{\Sph^{m-1}}  \int_{\Sph^{m-1}} K \Big( \sqrt{|sx_s - \sigma y_\sigma|^2 + |t x_t - \tau y_\tau|^2 }\Big ) \d y_\sigma \d y_\tau \,.
\end{equation}

First of all, it is easy to see that $J$ does not depend on $x_s$ nor $x_t$. Indeed, consider a
different point $(z_s, z_t)\in \Sph^{m-1} \times \Sph^{m-1}$ and let $M_s$ and $M_t$ be two
orthogonal transformations such that $M_s(x_s) = z_s$ and $M_t(x_t) = z_t$. Then, making the change
of variables $y_\sigma = M_s(\tilde{y}_\sigma)$ and $y_\tau = M_t(\tilde{y}_\tau)$, and using that
$M_s( \Sph^{m-1}) = M_t(\Sph^{m-1}) = \Sph^{m-1}$, we find out that
\begin{align*}
& \hspace{-1cm} J(z_s, z_t, s,t,\sigma, \tau) = \\
&= \int_{\Sph^{m-1}}  \int_{\Sph^{m-1}} K \Big( \sqrt{|s M_s(x_s) - \sigma y_\sigma|^2 + |t M_t(x_t) - \tau y_\tau|^2 }\Big) \d y_\sigma \d y_\tau \\
&= \int_{\Sph^{m-1}}  \int_{\Sph^{m-1}} K \Big( \sqrt{|s M_s(x_s) - \sigma M_s(\tilde{y}_\sigma)|^2 + |t M_t(x_t) - \tau M_t(\tilde{y}_\tau)|^2 }\Big) \d \tilde{y}_\sigma \d \tilde{y}_\tau \\
&= \int_{\Sph^{m-1}}  \int_{\Sph^{m-1}} K\Big ( \sqrt{|M_s(sx_s - \sigma \tilde{y}_\sigma)|^2 + |M_t(t x_t - \tau \tilde{y}_\tau)|^2 }\Big) \d \tilde{y}_\sigma \d \tilde{y}_\tau \\
&= \int_{\Sph^{m-1}}  \int_{\Sph^{m-1}} K\Big ( \sqrt{|sx_s - \sigma \tilde{y}_\sigma|^2 + |t x_t - \tau \tilde{y}_\tau|^2 }\Big) \d \tilde{y}_\sigma \d \tilde{y}_\tau \\
&= J(x_s, x_t, s,t,\sigma, \tau) \,.
\end{align*}

Therefore, we can replace $x_s$ and $x_t$ in \eqref{Eq:KernelSTVariablesProof1} by $e =(1,0,\ldots,
0) \in \Sph^{m-1}$. Thus, we have
\begin{equation}
\label{Eq:KernelSTVariablesProof2}
J(s,t,\sigma, \tau) := \int_{\Sph^{m-1}}  \int_{\Sph^{m-1}} K\Big( \sqrt{|s e - \sigma y_\sigma|^2 + |t e - \tau y_\tau|^2 }\Big) \d y_\sigma \d y_\tau \,.
\end{equation}
For an easier notation, we rename $\omega = y_\sigma$ and $\tilde\omega = y_\tau$, and thus we have
\begin{align*}
|s e - \sigma y_\sigma|^2 + |t e - \tau y_\tau|^2 &= |s e - \sigma \omega|^2 + |t e - \tau \tilde\omega|^2\\
&= s^2 +\sigma^2 - 2 s \sigma e \cdot \omega + t^2 + \tau^2 - 2 t \tau e\cdot \tilde\omega \\
&= s^2 +\sigma^2 - 2 s \sigma \omega_1 + t^2 + \tau^2 - 2t \tau\tilde\omega_1\,.
\end{align*}
Then, we can rewrite $J$ as
\begin{equation*}
\label{Eq:KernelSTVariablesProof3}
J(s,t,\sigma, \tau) := \int_{\Sph^{m-1}}  \int_{\Sph^{m-1}} K\Big( \sqrt{s^2+\sigma^2- 2 s \sigma \omega_1 + t^2 + \tau^2 - 2t \tau\tilde\omega_1}\Big) \d \omega \d \tilde\omega \,.
\end{equation*}
At this point we have to distinguish the cases $m=1$ and $m\geq 2$. For the fist one, since
$\Sph^{0} = \{-1,1\}$ we directly obtain \eqref{Eq:KernelInSTVariablesR2}. For the second one,
since the integrand only depends on $\omega_1$ and $\tilde\omega_1$, we proceed as follows
\begin{align*}
\label{Eq:KernelSTVariablesProof4}
J(s,t,\sigma, \tau) &= \int_{\Sph^{m-1}}  \int_{\Sph^{m-1}} K\Big( \sqrt{s^2+\sigma^2- 2 s \sigma \omega_1 + t^2 + \tau^2 - 2t \tau\tilde\omega_1}\Big) \d \omega \d \tilde\omega \,\\
&= \int_{-1}^1 \d \omega_1 \int_{\partial B_{\rho(\omega_1)}} \d \omega_2\cdot\cdot\cdot\d \omega_m \int_{-1}^1 \d \tilde\omega_1 \int_{\partial B_{\rho(\tilde\omega_1)}} \d \tilde\omega_2\cdot\cdot\cdot\d \tilde\omega_m  \\
& \quad \quad \quad \quad \quad K\Big( \sqrt{s^2+\sigma^2- 2 s \sigma \omega_1 + t^2 + \tau^2 - 2t \tau\tilde\omega_1}\Big) \, \\
&= \int_{-1}^1 \int_{-1}^1  |\partial B_{\rho(\omega_1)}| |\partial B_{\rho(\tilde\omega_1)}|\,\\
& \quad \quad \quad \quad \quad K\Big( \sqrt{s^2+\sigma^2- 2 s \sigma \omega_1 + t^2 + \tau^2 - 2t \tau\tilde\omega_1}\Big) \d \omega_1 \d \tilde\omega_1.
\end{align*}
where $\rho(r) = \sqrt{1-r^2}$. Finally, we obtain \eqref{Eq:KernelSTVariables2} once we replace
$|\partial B_{r}|=c_m\,r^{m-2}$, where $c_m$ is the measure of the boundary of the ball of radius one in
$\R^{m-1}$.
\end{proof}

In the case the operator is the fractional Laplacian we can obtain an alternative expression of the
kernel $J$ in terms of some hypergeometric functions.
\begin{lemma}
\label{Lemma:Appell} If $L_K = (-\Delta)^\s$ and $m\geq 2$, then
\begin{equation}
\label{Eq:Appell}
J(s,t,\sigma,\tau) = \frac{\pi^m\Gamma\left(\frac{m}{2}\right)^2}{\Gamma\left(\frac{m-1}{2}\right)^2\Gamma\left(\frac{m+1}{2}\right)^2} \frac{F_2\left( m+\s;\frac{m}{2},m;\frac{m}{2},m;\frac{4s\sigma}{(s+\sigma)^2+(t+\tau)^2},\frac{4t\tau}{(s+\sigma)^2+(t+\tau)^2} \right)}{[(s+\sigma)^2+(t+\tau)^2]^{m+\s}},
\end{equation}
where $F_2$ is the so-called Appell hypergeometric function (see \cite{Appell}).
\end{lemma}
Although we are not using the previous result in this work, we think that it could be very useful in future
works since we are writing the kernel in terms of functions that have already been studied and have
interesting well-known properties.


\begin{proof}
If we take $K(z) = |z|^{-2m-2\s}$ in \eqref{Eq:KernelSTVariables2} we get
\begin{align*}
J(s,t,\sigma, \tau) = c_m ^2  \int_{-1}^1  \int_{-1}^1  \frac{(1-\theta^2)^{\frac{m-2}{2}} (1-\overline{\theta}^2)^{\frac{m-2}{2}}}{(s^2 + t^2 + \sigma^2 + \tau^2 -2 s \sigma \theta -2 t \tau \overline{\theta})^{m+\s}} \d \theta \d \overline{\theta}\,.
\end{align*}
Then, if we make the change of variables $\theta = 2\varpi_1-1$ and $\overline{\theta}=2\varpi_2-1$
we arrive at
\begin{align*}
J(s,t,\sigma, \tau) &= \frac{2^{2m-4} c_m^2}{[(s+\sigma)^2+(t+\tau)^2]^{m+\s}} \int_0^1 \int_0^1
\frac{\varpi_1^\frac{m-2}{2} (1-\varpi_1)^\frac{m-2}{2} \varpi_2^\frac{m-2}{2}
(1-\varpi_2)^\frac{m-2}{2}}{\left(1-\frac{4s\sigma}{(s+\sigma)^2+(t+\tau)^2}\,\varpi_1-\frac{4t\tau}{(s+\sigma)^2+(t+\tau)^2}\,\varpi_2
\right)^{m+\s}} \d \varpi_1 \d \varpi_2 \\
&= \frac{2^{2m-4} c_m^2}{[(s+\sigma)^2+(t+\tau)^2]^{m+\s}} \frac{\Gamma\left(\frac{m}{2} \right)^4}{\Gamma(m)^2} \\
& \quad \quad \quad \quad F_2\left( m+\s;\frac{m}{2},m;\frac{m}{2},m;\frac{4s\sigma}{(s+\sigma)^2+(t+\tau)^2},\frac{4t\tau}{(s+\sigma)^2+(t+\tau)^2} \right).
\end{align*}
We finally obtain \eqref{Eq:Appell} by using the duplication formula for the $\Gamma$-function.
\end{proof}

Now we rewrite the kernel inequality \eqref{Eq:KernelInequality} in $(s,t)$ variables. We
do not present a proof of this result since it is identical to the one of
Proposition~\ref{Prop:KernelInequalitySufficientCondition} but changing the notation.

\begin{lemma}
\label{Lemma:KernelInequalityCone} Let $m\geq 1$ and let $J$ the kernel defined in
\eqref{Eq:KernelSTVariables2} with $K(\sqrt{\cdot})$ strictly convex. Then, if $s>t$ and $\sigma > \tau$, we have
\begin{equation*}
%\label{Eq:KernelInequalityCone}
J(s,t,\sigma, \tau) > J(s,t,\tau, \sigma)\,.
\end{equation*}
\end{lemma}

%\begin{proof}
%We will just consider some simplifications of \eqref{Eq:KernelInequalityCone}. Eventually, we will
%use Lemma~\ref{Lemma:InequalitConvexFunctions} to deduce the desired inequality.
%
%First of all, note that it is enough to show that
%\begin{equation}
%\label{Eq:KernelInequalitySimplified1}
%\int_{-1}^1  \int_{-1}^1  (1-\alpha^2)^{\frac{m-3}{2}} (1-\beta^2)^{\frac{m-3}{2}}  \left \{\tilde{K}\Big(\sqrt{1 -2 s \sigma \alpha -2 t \tau \beta}\Big) - \tilde{K}\Big(\sqrt{1 -2 s \tau \alpha -2 t \sigma \beta}\Big)  \right \}\d \alpha \d \beta \geq 0\,,
%\end{equation}
%Where $\tilde{K}(z) = K((s^2 + t^2 + \sigma^2 + \tau^2)z)$. To see that this is equivalent to
%\eqref{Eq:KernelInequalityCone}, we just normalize the variables in the following way:
%$$
%\tilde{s} = \dfrac{s}{\sqrt{s^2 + t^2 + \sigma^2 + \tau^2}}\,, \quad \tilde{t} = \dfrac{t}{\sqrt{s^2 + t^2 + \sigma^2 + \tau^2}}\,,
%$$
%$$
%\tilde{\sigma} = \dfrac{\sigma}{\sqrt{s^2 + t^2 + \sigma^2 + \tau^2}}\, \quad \textrm{ and } \quad \tilde{\tau} = \dfrac{\tau}{\sqrt{s^2 + t^2 + \sigma^2 + \tau^2}}\,.
%$$
%
%The second simplification is the following. Since $s>t>0$ and $\sigma > \tau>0$, we may write
%$$
%s = (1+\varepsilon) t \quad \textrm{ and} \quad \sigma = (1 + \delta) \tau
%$$
%with $\varepsilon$, $\delta > 0$. Then, \eqref{Eq:KernelInequalitySimplified1} is equivalent to
%\begin{equation}
%\label{Eq:KernelInequalitySimplified2}
%\int_{-1}^1  \int_{-1}^1  (1-\alpha^2)^{\frac{m-3}{2}} (1-\beta^2)^{\frac{m-3}{2}}  \left \{\tilde{K}\Big(\sqrt{1 -2 t \tau \{(1+\varepsilon)(1+\delta) \alpha + \beta\}}\Big) - \tilde{K}\Big(\sqrt{1 -2 t \tau \{(1+\varepsilon) \alpha + (1+\delta)\beta\}}\Big)  \right \}\d \alpha \d \beta \geq 0\,.
%\end{equation}
%
%Now, we make some changes of variables to reduce the domain of integration. First, we divide
%$(-1,1)^2 \setminus \{|\alpha| = |\beta|\}$ into four sectors:
%$$
%Q_1 = \{\alpha > |\beta| \}\,, \quad Q_2 = \{\beta > |\alpha| \}\,, \quad Q_3 = \{\alpha < -|\beta|\}\,, \quad \textrm{ and } \quad Q_4 = \{ \beta < -|\alpha|\}\,.
%$$
%Consider the changes
%\begin{align*}
%  \psi_2 \colon Q_2 \  &\to \ Q_1 \\
%  \ (\alpha,\beta) &\mapsto (\beta,\alpha)
%\end{align*}
%\begin{align*}
%  \psi_3 \colon Q_3 \  &\to \ Q_1 \\
%  \ (\alpha,\beta) &\mapsto (-\alpha,-\beta)
%\end{align*}
%\begin{align*}
%  \psi_4 \colon Q_4 \  &\to \ Q_1 \\
%  \ (\alpha,\beta) &\mapsto (-\beta,-\alpha)
%\end{align*}
%Then, \eqref{Eq:KernelInequalitySimplified2} is now equivalent to show
%\begin{align*}
%\int \int_{Q_1} \left\{
%  \tilde{K}\Big(\sqrt{1 -2 t \tau \{(1+\varepsilon)(1+\delta) \alpha + \beta\}}\Big)
%+ \tilde{K}\Big(\sqrt{1 +2 t \tau \{(1+\varepsilon)(1+\delta) \alpha + \beta\}}\Big) \right. \\
%+ \tilde{K}\Big(\sqrt{1 -2 t \tau \{(1+\varepsilon)(1+\delta) \beta + \alpha\}}\Big)
%+ \tilde{K}\Big(\sqrt{1 +2 t \tau \{(1+\varepsilon)(1+\delta) \beta + \alpha\}}\Big) \\
%- \tilde{K}\Big(\sqrt{1 -2 t \tau \{(1+\varepsilon) \alpha + (1+\delta)\beta\}}\Big)
%- \tilde{K}\Big(\sqrt{1 +2 t \tau \{(1+\varepsilon) \alpha + (1+\delta)\beta\}}\Big) \\
%\left.- \tilde{K}\Big(\sqrt{1 -2 t \tau \{(1+\varepsilon) \beta + (1+\delta)\alpha\}}\Big)
%- \tilde{K}\Big(\sqrt{1 +2 t \tau \{(1+\varepsilon) \beta + (1+\delta)\alpha\}}\Big)
%\right\} \cdot \\
%\cdot (1-\alpha^2)^{\frac{m-3}{2}} (1-\beta^2)^{\frac{m-3}{2}} \d \alpha \d \beta \geq 0\,.
%\end{align*}
%Note that we are not considering anymore the set $\{|\alpha| = |\beta|\}$, that has measure zero.
%
%Now, if we call
%$$
%g(z) := \tilde{K}\Big(\sqrt{1 -2 t \tau z}\Big)
%+ \tilde{K}\Big(\sqrt{1 +2 t \tau z }\Big)\,,
%$$
%the previous inequality reads
%\begin{equation}
%\label{Eq:KernelInequalitySimplified3}
%\begin{split}
%	\int \int_{Q_1} \left\{
%	g\Big((1+\varepsilon)(1+\delta) \alpha + \beta\Big)
%	+ g\Big((1+\varepsilon)(1+\delta) \beta + \alpha\Big)
%	\right.\\
%	\left.
%	- g\Big((1+\varepsilon) \alpha + (1+\delta)\beta\Big)
%	- g\Big((1+\varepsilon) \beta + (1+\delta)\alpha\Big)
%	\right\} \cdot \\
%	\cdot (1-\alpha^2)^{\frac{m-3}{2}} (1-\beta^2)^{\frac{m-3}{2}} \d \alpha \d \beta \geq 0\,.
%\end{split}
%\end{equation}
%We claim that
%\begin{equation}
%\label{Eq:KernelInequalityLastSimplification}
%g\Big((1+\varepsilon)(1+\delta) \alpha + \beta\Big)
%+ g\Big((1+\varepsilon)(1+\delta) \beta + \alpha\Big)
% \geq
%g\Big((1+\varepsilon) \alpha + (1+\delta)\beta\Big)
%+g\Big((1+\varepsilon) \beta + (1+\delta)\alpha\Big) \,.
%\end{equation}
%This will conclude the proof.
%
%To prove the claim, we want to use Lemma~\ref{Lemma:InequalitConvexFunctions} with
%$$
%\begin{array}{cc}
%A = (1+\varepsilon)(1+\delta) \alpha + \beta\,, &
%B = (1+\varepsilon) \alpha + (1+\delta)\beta\,, \\
%C = (1+\delta)\alpha + (1+\varepsilon) \beta\,, &
%D = \alpha + (1+\varepsilon)(1+\delta) \beta\,.
%\end{array}
%$$
%Note that, since $\tilde{K}$ and $\sqrt{1 - z}$ are nonincreasing, $g$ is nondecreasing $[0,1)$.
%Moreover, since $\tilde{K}$ is convex and nonincreasing and $\sqrt{1 - z}$ is concave, $g$ is
%convex in $[0,1)$. But since $A$, $B$, $C$ and $D$ $\in (-1, 1)$ ---by the normalizations we have
%made--- and $g$ is even, we cannot apply directly Lemma~\ref{Lemma:InequalitConvexFunctions} ($g$
%is nonincreasing in $(-1,0]$). Instead, if we do it for  $|A|$, $|B|$, $|C|$ and $|D|$, then we can
%use the lemma in $[0,1)$. Hence, we should check that
%$$
%\begin{cases}
%|A| \geq |B|,\ |C|, \ |D|\,, \\
%|A| + |D| \geq |B| + |C|\,.
%\end{cases}
%$$
%The verification of these inequalities is a simple but tedious computation and it is presented in
%the appendix (see Lemma~\ref{Lemma:ComputationABCD}). Once we have these inequalities, we use
%Lemma~\ref{Lemma:InequalitConvexFunctions} to deduce
%$$
%g(|A|) + g(|D|) \geq g(|B|) + g(|C|)\,,
%$$
%which is equivalent to \eqref{Eq:KernelInequalityLastSimplification} since $g$ is even. This
%concludes the proof of \eqref{Eq:KernelInequalityCone}.
%
%
%
%Finally, to justify that the inequality in \eqref{Eq:KernelInequalityCone} is strict up to a set of
%measure zero, we consider the points where $J(s,t,\sigma, \tau) = J(s,t,\tau,\sigma)$. Following
%the previous arguments, this is equivalent to say that we have an equality in
%\eqref{Eq:KernelInequalitySimplified2}, and since the integrand of that equality is nonnegative, it
%is equivalent to say that we have an equality in \eqref{Eq:KernelInequalityLastSimplification} up
%to a set of measure zero. Then, we take into account the following: since the function $\sqrt{1-z}$
%is increasing and strictly convex and the kernel $K$ is decreasing, then $g''>0$ in $(0,1)$.
%Therefore, in view of Remark~\eqref{Remark:StrictInequalitConvexFunctions}, the equality $g(A) +
%g(D) = g(B) + g(C)$ is only possible in the case $A=B=C=D$, and it is easy to verify that this
%cannot happen unless $A=B=C=D=0$\todo{Check again}. This is equivalent to $s=t$ and $\sigma=\tau$,
%something that is impossible in $\ocal$.
%
%%, under these conditions, $\varepsilon = \delta = (\sqrt{5} - 1)/2$. If we fix such values of $\varepsilon$ and $\delta$ we have a set of measure zero, $ \{2 \tilde{s} = (1 + \sqrt{5}) \tilde{t} \} \cap \{2 \tilde{\sigma} = (1 + \sqrt{5}) \tilde{\tau} \}$, in the space of the normalized parameters $\tilde{s}$, $\tilde{t}$, $\tilde{\sigma}$, $\tilde{\tau}$, as well as in the space of original ones.
%\end{proof}
